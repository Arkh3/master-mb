{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e360b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements auto-encoding variational Bayes.\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.norm as norm\n",
    "    \n",
    "from autograd import grad\n",
    "from data import load_mnist\n",
    "from data import save_images as s_images\n",
    "from autograd.misc import flatten # This is used to flatten the params (transforms a list into a numpy array)\n",
    "\n",
    "# images is an array with one row per image, file_name is the png file on which to save the images\n",
    "\n",
    "def save_images(images, file_name): return s_images(images, file_name, vmin = 0.0, vmax = 1.0)\n",
    "\n",
    "# Sigmoid activiation function to estimate probabilities\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# Relu activation function for non-linearity\n",
    "\n",
    "def relu(x):    return np.maximum(0, x)\n",
    "\n",
    "# This function intializes the parameters of a deep neural network\n",
    "\n",
    "def init_net_params(layer_sizes, scale = 1e-2):\n",
    "\n",
    "    \"\"\"Build a (weights, biases) tuples for all layers.\"\"\"\n",
    "\n",
    "    return [(scale * npr.randn(m, n),   # weight matrix\n",
    "             scale * npr.randn(n))      # bias vector\n",
    "            for m, n in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "\n",
    "# This will be used to normalize the activations of the NN\n",
    "\n",
    "# This computes the output of a deep neuralnetwork with params a list with pairs of weights and biases\n",
    "\n",
    "def neural_net_predict(params, inputs):\n",
    "\n",
    "    \"\"\"Params is a list of (weights, bias) tuples.\n",
    "       inputs is an (N x D) matrix.\n",
    "       Applies batch normalization to every layer but the last.\"\"\"\n",
    "\n",
    "    for W, b in params[:-1]:\n",
    "        outputs = np.dot(inputs, W) + b  # linear transformation\n",
    "        inputs = relu(outputs)         # nonlinear transformation\n",
    "\n",
    "    # Last layer is linear\n",
    "\n",
    "    outW, outb = params[-1]\n",
    "    outputs = np.dot(inputs, outW) + outb\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# This implements the reparametrization trick\n",
    "\n",
    "def sample_latent_variables_from_posterior(encoder_output):\n",
    "\n",
    "    # Params of a diagonal Gaussian.\n",
    "\n",
    "    D = np.shape(encoder_output)[-1] // 2\n",
    "    mean, log_std = encoder_output[:, :D], encoder_output[:, D:]\n",
    "\n",
    "    # -------------------------\n",
    "    # Reparametrization trick to generate one sample from q(z|x) per each batch datapoint\n",
    "    z_i = mean + np.exp(log_std) * npr.randn(*mean.shape) # Equation 15\n",
    "\n",
    "    # -------------------------\n",
    "    # The output of this function is a matrix of size the batch x the number of latent dimensions\n",
    "    return z_i\n",
    "\n",
    "# This evlauates the log of the term that depends on the data\n",
    "\n",
    "def bernoulli_log_prob(targets, logits):\n",
    "\n",
    "    # logits are in R\n",
    "    # Targets must be between 0 and 1\n",
    "\n",
    "    # TODO compute the log probability of the targets given the generator output specified in logits\n",
    "    # sum the probabilities across the dimensions of each image in the batch. The output of this function \n",
    "    # should be a vector of size the batch size\n",
    "\n",
    "    sig_logits = sigmoid(logits)\n",
    "\n",
    "    return np.sum(np.log(targets * sig_logits + (1 - targets) * (1 - sig_logits)), axis=1)\n",
    "\n",
    "# This evaluates the KL between q and the prior\n",
    "\n",
    "def compute_KL(q_means_and_log_stds):\n",
    "    \n",
    "    D = np.shape(q_means_and_log_stds)[-1] // 2\n",
    "    mean, log_std = q_means_and_log_stds[:, :D], q_means_and_log_stds[:, D:]\n",
    "\n",
    "    # TODO compute the KL divergence between q(z|x) and the prior (use a standard Gaussian for the prior)\n",
    "    # Use the fact that the KL divervence is the sum of KL divergence of the marginals if q and p factorize\n",
    "    # The output of this function should be a vector of size the batch size\n",
    "\n",
    "    variance = np.exp(log_std * 2)\n",
    "\n",
    "    return .5 * np.sum((variance + mean**2 - 1 - 2 * log_std), axis=1)\n",
    "\n",
    "# This evaluates the lower bound\n",
    "\n",
    "def vae_lower_bound(gen_params, rec_params, data):\n",
    "    # Compute a noisy estiamte of the lower bound by using a single Monte Carlo sample:\n",
    "    \n",
    "    # -------------------------\n",
    "    # 1 - compute the encoder output using neural_net_predict given the data and rec_params\n",
    "    encoder_output = neural_net_predict(rec_params, data)\n",
    "    \n",
    "    # 2 - sample the latent variables associated to the batch in data \n",
    "    #     (use sample_latent_variables_from_posterior and the encoder output)\n",
    "    sampled_latent_variables = sample_latent_variables_from_posterior(encoder_output)\n",
    "\n",
    "    # 3 - use the sampled latent variables to reconstruct the image and to compute the log_prob of the actual data\n",
    "    #     (use neural_net_predict for that)\n",
    "    decoder_output = neural_net_predict(gen_params, sampled_latent_variables)\n",
    "\n",
    "    log_prob = bernoulli_log_prob(data, decoder_output)\n",
    "\n",
    "    # 4 - compute the KL divergence between q(z|x) and the prior (use compute_KL for that)\n",
    "    divergence = compute_KL(encoder_output)\n",
    "\n",
    "    # 5 - return an average estimate (per batch point) of the lower bound by substracting the KL to the data dependent term\n",
    "    lower_bound_estimate = np.mean(log_prob - divergence)\n",
    "    # -------------------------\n",
    "\n",
    "    return lower_bound_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba98ac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Epoch: 0 ELBO: -2.220131e+02\n",
      "Epoch: 1 ELBO: -1.934818e+02\n",
      "Epoch: 2 ELBO: -1.805705e+02\n",
      "Epoch: 3 ELBO: -1.664317e+02\n",
      "Epoch: 4 ELBO: -1.548852e+02\n",
      "Epoch: 5 ELBO: -1.463868e+02\n",
      "Epoch: 6 ELBO: -1.390776e+02\n",
      "Epoch: 7 ELBO: -1.343981e+02\n",
      "Epoch: 8 ELBO: -1.303842e+02\n",
      "Epoch: 9 ELBO: -1.261567e+02\n",
      "Epoch: 10 ELBO: -1.228824e+02\n",
      "Epoch: 11 ELBO: -1.205947e+02\n",
      "Epoch: 12 ELBO: -1.190836e+02\n",
      "Epoch: 13 ELBO: -1.177239e+02\n",
      "Epoch: 14 ELBO: -1.167119e+02\n",
      "Epoch: 15 ELBO: -1.159205e+02\n",
      "Epoch: 16 ELBO: -1.151034e+02\n",
      "Epoch: 17 ELBO: -1.143162e+02\n",
      "Epoch: 18 ELBO: -1.135846e+02\n",
      "Epoch: 19 ELBO: -1.129953e+02\n",
      "Epoch: 20 ELBO: -1.124856e+02\n",
      "Epoch: 21 ELBO: -1.117956e+02\n",
      "Epoch: 22 ELBO: -1.110689e+02\n",
      "Epoch: 23 ELBO: -1.106104e+02\n",
      "Epoch: 24 ELBO: -1.102020e+02\n",
      "Epoch: 25 ELBO: -1.098817e+02\n",
      "Epoch: 26 ELBO: -1.094777e+02\n",
      "Epoch: 27 ELBO: -1.092068e+02\n",
      "Epoch: 28 ELBO: -1.088990e+02\n",
      "Epoch: 29 ELBO: -1.087090e+02\n"
     ]
    }
   ],
   "source": [
    "# Model hyper-parameters\n",
    "\n",
    "npr.seed(0) # We fix the random seed for reproducibility\n",
    "\n",
    "latent_dim = 50\n",
    "data_dim = 784  # How many pixels in each image (28x28).\n",
    "n_units = 200\n",
    "n_layers = 2\n",
    "\n",
    "gen_layer_sizes = [ latent_dim ] + [ n_units for i in range(n_layers) ] + [ data_dim ]\n",
    "rec_layer_sizes = [ data_dim ]  + [ n_units for i in range(n_layers) ] + [ latent_dim * 2 ]\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "batch_size = 200\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "\n",
    "N, train_images, _, test_images, _ = load_mnist()\n",
    "\n",
    "# Parameters for the generator network p(x|z)\n",
    "\n",
    "init_gen_params = init_net_params(gen_layer_sizes)\n",
    "\n",
    "# Parameters for the recognition network p(z|x)\n",
    "\n",
    "init_rec_params = init_net_params(rec_layer_sizes)\n",
    "\n",
    "combined_params_init = (init_gen_params, init_rec_params)\n",
    "\n",
    "num_batches = int(np.ceil(len(train_images) / batch_size))\n",
    "\n",
    "# We flatten the parameters (transform the lists or tupples into numpy arrays)\n",
    "\n",
    "flattened_combined_params_init, unflat_params = flatten(combined_params_init)\n",
    "\n",
    "# Actual objective to optimize that receives flattened params\n",
    "\n",
    "def objective(flattened_combined_params):\n",
    "\n",
    "    combined_params = unflat_params(flattened_combined_params)\n",
    "    data_idx = batch\n",
    "    gen_params, rec_params = combined_params\n",
    "\n",
    "    # We binarize the data\n",
    "\n",
    "    on = train_images[ data_idx ,: ] > npr.uniform(size = train_images[ data_idx ,: ].shape)\n",
    "    images = train_images[ data_idx, : ] * 0.0\n",
    "    images[ on ] = 1.0\n",
    "\n",
    "    return vae_lower_bound(gen_params, rec_params, images) \n",
    "\n",
    "# Get gradients of objective using autograd.\n",
    "\n",
    "objective_grad = grad(objective)\n",
    "flattened_current_params = flattened_combined_params_init\n",
    "\n",
    "# ADAM parameters\n",
    "\n",
    "# -------------------------\n",
    "# Initial values for the ADAM parameters (including the m and v vectors)\n",
    "alpha = 0.001\n",
    "beta1 =  0.9    # [0, 1)\n",
    "beta2 =  0.999  # [0, 1)\n",
    "epsilon = 1e-8\n",
    "\n",
    "m = np.zeros_like(flattened_current_params)\n",
    "v = np.zeros_like(flattened_current_params)\n",
    "\n",
    "t = 1\n",
    "# -------------------------\n",
    "\n",
    "# We do the actual training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    elbo_est = 0.0\n",
    "\n",
    "    for n_batch in range(int(np.ceil(N / batch_size))):\n",
    "\n",
    "        batch = np.arange(batch_size * n_batch, np.minimum(N, batch_size * (n_batch + 1)))\n",
    "        grad = objective_grad(flattened_current_params)\n",
    "\n",
    "        # -------------------------\n",
    "        # Use the estimated noisy gradient in grad to update the paramters using the ADAM updates\n",
    "        #import pdb; pdb.set_trace() \n",
    "\n",
    "        m = beta1 * m + (1 - beta1) * grad\n",
    "        \n",
    "        v = beta2 * v + (1 - beta2) * grad**2\n",
    "\n",
    "        m_est = m / (1 - beta1**t)\n",
    "        v_est = v / (1 - beta2**t)\n",
    "\n",
    "        flattened_current_params += alpha * m_est / (np.sqrt(v_est) + epsilon)\n",
    "        \n",
    "        # -------------------------\n",
    "\n",
    "        elbo_est += objective(flattened_current_params)\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    print(\"Epoch: %d ELBO: %e\" % (epoch, elbo_est / np.ceil(N / batch_size)))\n",
    "\n",
    "# We obtain the final trained parameters\n",
    "\n",
    "gen_params, rec_params = unflat_params(flattened_current_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ec68ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2216\u001b[0m                 \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_artists\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2218\u001b[0;31m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m                 \u001b[0mbbox_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36mget_default_bbox_extra_artists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2208\u001b[0m                 \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0;31m# we don't want the figure's patch to influence the bbox calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m         \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtask 3.1: Generate 25 images from prior (use neural_net_predict) and save them using save_images\n",
    "num_images = 25\n",
    "\n",
    "# Prior sampling\n",
    "z = npr.randn(num_images, latent_dim)\n",
    "\n",
    "# Image generation\n",
    "x = neural_net_predict(gen_params, z)\n",
    "images = sigmoid(x)\n",
    "save_images(images, \"output_images/3_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fa224d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2216\u001b[0m                 \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_artists\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2218\u001b[0;31m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m                 \u001b[0mbbox_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36mget_default_bbox_extra_artists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2208\u001b[0m                 \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0;31m# we don't want the figure's patch to influence the bbox calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m         \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtask 3.2: Generate image reconstructions for the first 10 test images (use neural_net_predict for each model) \n",
    "# and save them alongside with the original image using save_images\n",
    "images_to_reconstruct = test_images[:10]\n",
    "\n",
    "encoder_output = neural_net_predict(rec_params, images_to_reconstruct)\n",
    "z2 = sample_latent_variables_from_posterior(encoder_output)\n",
    "\n",
    "x2 = neural_net_predict(gen_params, z2)\n",
    "\n",
    "images_reconstructed = sigmoid(x2)\n",
    "\n",
    "images_to_save = np.append(images_to_reconstruct, images_reconstructed, axis=0)\n",
    "\n",
    "save_images(images_to_save, \"output_images/3_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62a9fd46",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2216\u001b[0m                 \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_artists\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2218\u001b[0;31m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m                 \u001b[0mbbox_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/antf/services/conda3/envs/env_bayesianos/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36mget_default_bbox_extra_artists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2208\u001b[0m                 \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0;31m# we don't want the figure's patch to influence the bbox calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m         \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subtask 3.2: Generate 5 interpolations from the first test image to the second test image, \n",
    "# for the third to the fourth and so on until 5 interpolations\n",
    "# are computed in latent space and save them using save images.\n",
    "\n",
    "num_interpolations = 5\n",
    "\n",
    "for i in range(num_interpolations):\n",
    "    image1 = test_images[i * 2]\n",
    "    image2 = test_images[i * 2 + 1]\n",
    "\n",
    "    # Use mean of the recognition model as the latent representation.\n",
    "    encoder_output1 = neural_net_predict(rec_params, image1)\n",
    "    encoder_output2 = neural_net_predict(rec_params, image2)\n",
    "\n",
    "    D1 = np.shape(encoder_output1)[-1] // 2\n",
    "    mean1 = encoder_output1[:D1]\n",
    "\n",
    "    D2 = np.shape(encoder_output2)[-1] // 2\n",
    "    mean2 = encoder_output2[:D2]\n",
    "\n",
    "    # To interpolate from image I to image G use a convex conbination. Namely,\n",
    "    # I * s + (1-s) * G where s is a sequence of numbers from 0 to 1 obtained by numpy.linspace\n",
    "    interpolations = [mean2 * s + (1 - s) * mean1 for s in np.linspace(0.0, 1.0, 25)]\n",
    "\n",
    "    interpolated_images = neural_net_predict(gen_params, interpolations)\n",
    "\n",
    "    # Use a different file name to store the images of each iterpolation.\n",
    "    save_images(interpolated_images, \"output_images/interpolation_{}.png\".format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bayesianos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
